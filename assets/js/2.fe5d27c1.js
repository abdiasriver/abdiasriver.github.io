(window.webpackJsonp=window.webpackJsonp||[]).push([[2],{180:function(t,e){t.exports="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAI0AAAAkCAYAAAC0TbmDAAAFQElEQVR4nO2Z608cVRiH+zdRJVq10faDFxpiUNPWGx8sxmiqqWhiUpNaTay2GoytiYUi3QoLpVCakorQSEsttEDbUNruhWUvMMvemN1ld2Z3Z+f288Oyy84wy85ZS5F6Jnk+cGbmPbdnznnPsqWq2QYKhYQtG90AyuaDSkMhhkpDIYZKQyGGSkMhhkpDIYZKQyGGSkMhhkpDIYZKQyGGSkMhpmJpDl1dwGQghclACoeuLmx4R/4LjPt5tE2xj009pahYmluBFPLXrUCq4gbssDjRPh0FkxCRlVWEeQljDI8Dg/OPbBCuzXHouBfdNJP5MOr5N33eUGlebJ9BkBMR5ER8cy2Ad/u8qL/gxfGJMNi0jCdbjN+rPkWl+d9KM+xNgk3L2H7asereDotTM0hn78dw0bmEuCBjsqi+ppthMAkRgqzCHRPw1UhAE6dxiMF0OA1OVBAXZIz4OOzqdBXuX3QuQX/VnZ01FdtoMtuno+h+EAMnKlgSZJyeYrG16BknK6DpZljz3uBsAn2OuKbshxshzC1lISoqIikJliJJ9NLsH5gHJyr48sqCqXFZq88PVZo9vW7s6/cVcLCZQoUONqO5t6fXXTbeM7/ZIanAicmIqS9LUoDDIwFUn8q9W9Vsw8nbi2ASIj4emMeuThc+u8wgmVXw+WWm8O7BYT8ODM6jtsuF3T1uDLkTcLKCZiKNvjozsY3ayYsK2qZY1Ha60DjEgMsq+PFGiEialjuL4EQFX48EUNvlQv0FL74bDRpKc3DYD15U8Mmf80RtX/eVZk+ve5WZ5a5y4uzuycVsHCo9CcWDNO7nNWVPt9qRkVR8eGlOU/7rrQjGGL5krG2tdsgq8Ma5lfbpB7DS2ON+Hg42oyk7PhFGmJdMS7Ot1Y6MrGokMaqnbYrFsbEQklkF7130Ebd93aVp6PcRS9PQ71szJqk0+g7u7fWUrJtJiIXnXj/nxoiPQywjQy16Zv/AypepH0CzsY3a2f0gpinbtzx2z7U5TEnz5nLddd2lt4txP48QLyErq9jb66loXNZdmhqri0CX3FVjda0Z89k2ByQV+MXk9qRP/N46nxuc4hXDiCAn4rw9jhqrC9UtNmxttkFSgE8HSy/VZmObkaZBJ42dzayS5rInWZAmX3c5aYa9SSymJVh1E2+27Y8kEd5+2oGGfl8BJysUBHGyguaeUWJrxLA3iWiJRPgFXSKslya/jJ+YKC3dSx0zAIDarhWB8ytcsTTD3iS67seIYpeaTLvB9hRJrWxPY8zqvsxEhYq2p7ruWbBpWTP5Ztuu7/O6SKPnYZyeXu6YQYiXEFg+cr/T50H9BS9+HtceuUsdMU/eXkRGUvH9aBCvnp3F7h43vv07iKOjucSzusWGhKDg2Fju7+ctDkwspKCoWml+n47ifiSDGqsLOyxOPNFSPnapyTRKhItXlqabYTBJETvPOLG12YajoyFIKjSJcOtyInx4JIDaThfe7vPgyHXjRNhIHDNtN+rzppCmqtmGnWec6LgXBZMUC8fLa3Mc3i/Kidb6XeLI9SDcMQGioiKekTHu5/HRHytJ4AeX5uCOCYikJHjiWXzxlx9pSdVI84rVhTvBFDJSLuvJHz/LxTaSpn06il57HJyoICEosNxlNRPyVKsdfY444hkZQT53lC7envL8tCyXpABhXtL0Xz8er3XPIpqW0TEdNT0upfq8KaShbD4qlqah34crviSu+JJlT0qUxwv6X24KMVQaCjFUGgoxVBoKMVQaCjFUGgoxVBoKMVQaCjFUGgoxVBoKMVQaCjH/AGiEBApFN88xAAAAAElFTkSuQmCC"},181:function(t,e,a){t.exports=a.p+"assets/img/02-name-bucket.9c0cb906.png"},182:function(t,e,a){t.exports=a.p+"assets/img/03-public-bucket.f9df4738.png"},183:function(t,e,a){t.exports=a.p+"assets/img/04-bucket-list.ce9cb8c9.png"},184:function(t,e,a){t.exports=a.p+"assets/img/05-create-user.59ab3d94.png"},185:function(t,e,a){t.exports=a.p+"assets/img/06-permissions.8403b414.png"},186:function(t,e,a){t.exports=a.p+"assets/img/07-review.aa11b2cf.png"},187:function(t,e,a){t.exports=a.p+"assets/img/08-access-key.4167e633.png"},204:function(t,e,a){"use strict";a.r(e);var s=[function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"automating-arch-linux-part-1-hosting-an-arch-linux-repo-in-an-amazon-s3-bucket"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#automating-arch-linux-part-1-hosting-an-arch-linux-repo-in-an-amazon-s3-bucket","aria-hidden":"true"}},[this._v("#")]),this._v(" Automating Arch Linux Part 1: Hosting an Arch Linux Repo in an Amazon S3 Bucket")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"tip custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("Update on 2018-05-20")]),t._v(" "),a("p",[t._v("I have updated this guide to switch from "),a("code",[t._v("repose")]),t._v(" and "),a("code",[t._v("s3fs")]),t._v(" to "),a("code",[t._v("repo-add")]),t._v(" and\n"),a("code",[t._v("s3cmd")]),t._v(" due to a number of limitation in "),a("code",[t._v("repose")]),t._v(" and the fact that "),a("code",[t._v("aurutils")]),t._v("\nis dropping support for it as well as some instabilities with "),a("code",[t._v("s3fs")]),t._v(" on weaker\ninternet connections.")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("li",[e("strong",[this._v("Part 1:")]),this._v(" "),e("em",[this._v("Hosting an Arch Linux Repo in an Amazon S3 Bucket")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"danger custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Although everything we are going to do in this post will fit inside the "),a("strong",[t._v("AWS\nfree tier")]),t._v(", it "),a("strong",[t._v("only lasts")]),t._v(" for "),a("strong",[t._v("12 months")]),t._v(". Make sure to "),a("strong",[t._v("delete")]),t._v(" any\n"),a("strong",[t._v("resources")]),t._v(" you create once you are done to avoid an "),a("strong",[t._v("unexpected charge")]),t._v("\nfrom AWS way in the future. Even without the free tier, it should only cost no\nmore than a few dollars a month to maintain the bucket - even with a very large\nrepository. You can also use alternatives like Digital Oceans Spaces, Google\nCloud or a static file web server.")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"dependencies"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#dependencies","aria-hidden":"true"}},[this._v("#")]),this._v(" Dependencies")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("We only require a few packages to get us going, of which only "),e("code",[this._v("aurutils")]),this._v(" needs to\nbe installed from AUR. It will be the only package we are required to\nbuild and install manually.")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{attrs:{class:"token function"}},[t._v("sudo")]),t._v(" pacman -S --needed s3cmd base-devel\n"),a("span",{attrs:{class:"token function"}},[t._v("wget")]),t._v(" https://aur.archlinux.org/cgit/aur.git/snapshot/aurutils.tar.gz\n"),a("span",{attrs:{class:"token function"}},[t._v("tar")]),t._v(" -xf aurutils.tar.gz\n"),a("span",{attrs:{class:"token function"}},[t._v("cd")]),t._v(" aurutils\nmakepkg -sci\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("If you get the following error while running "),e("code",[this._v("makepkg")]),this._v(".")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{attrs:{class:"token operator"}},[t._v("==")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),t._v(" Verifying "),a("span",{attrs:{class:"token function"}},[t._v("source")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("file")]),t._v(" signatures with gpg"),a("span",{attrs:{class:"token punctuation"}},[t._v("..")]),t._v(".\n    aurutils-1.5.3.tar.gz "),a("span",{attrs:{class:"token punctuation"}},[t._v("..")]),t._v(". FAILED "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unknown public key 6BC26A17B9B7018A"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token operator"}},[t._v("==")]),a("span",{attrs:{class:"token operator"}},[t._v(">")]),t._v(" ERROR: One or "),a("span",{attrs:{class:"token function"}},[t._v("more")]),t._v(" PGP signatures could not be verified"),a("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Simply download the missing key with the following before running "),e("code",[this._v("makepkg")]),this._v("\nabove.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[this._v("gpg --recv-key 6BC26A17B9B7018A\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"creating-the-amazon-s3-bucket"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#creating-the-amazon-s3-bucket","aria-hidden":"true"}},[this._v("#")]),this._v(" Creating the Amazon S3 Bucket")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(180),alt:"Create Bucket"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(181),alt:"Name the Bucket"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Then click on Next twice to get to (3) Set permissions and make the bucket\npublic. This will allow anyone in the world to read the bucket and thus allows\n"),e("code",[this._v("pacman")]),this._v(" to download the packages anonymously.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(182),alt:"Public Bucket"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(183),alt:"Bucket List"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"access-credentials"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#access-credentials","aria-hidden":"true"}},[this._v("#")]),this._v(" Access Credentials")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(184),alt:"Account Name"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Click Next to head to the permission page then "),e("em",[this._v("Attach existing policies\ndirectly")]),this._v(". Search for "),e("em",[this._v("S3")]),this._v(" and check "),e("em",[this._v("AmazonS3FullAccess")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(185),alt:"Account Permissions"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Click "),e("em",[this._v("Next")]),this._v(" and on the review page double check it has "),e("em",[this._v("Programmatic access")]),this._v("\nand "),e("em",[this._v("AmazonS3FullAccess")]),this._v(".")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(186),alt:"Account Review"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Click "),e("em",[this._v("Create User")]),this._v(" to get the access key. Take note of the "),e("em",[this._v("Access key ID")]),this._v(" as\nwell as the "),e("em",[this._v("Secret access key")]),this._v(". Ensure you save these somewhere, once you\nleave this page you will not have access to the secret key through the AWS\nconsole and will have to regenerate a new key.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[e("img",{attrs:{src:a(187),alt:"Account Secret"}})])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Save it to "),e("code",[this._v("~/.s3cfg")]),this._v(" in the form")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-ini extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ini"}},[a("code",[a("span",{attrs:{class:"token selector"}},[t._v("[default]")]),t._v("\n"),a("span",{attrs:{class:"token constant"}},[t._v("access_key")]),t._v(" "),a("span",{attrs:{class:"token attr-value"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" <ACCESS_KEY>")]),t._v("\n"),a("span",{attrs:{class:"token constant"}},[t._v("secret_key")]),t._v(" "),a("span",{attrs:{class:"token attr-value"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" <SECRET_KEY>")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{attrs:{class:"token function"}},[this._v("chmod")]),this._v(" 0600 ~/.s3cfg\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"aurutils-building-and-managing-packages"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#aurutils-building-and-managing-packages","aria-hidden":"true"}},[this._v("#")]),this._v(" Aurutils - Building and Managing Packages")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Aurutils contains a suite of utilities that can be used to manage a repo of AUR\npackages. The two main utilities we will use are "),e("code",[this._v("aursearch")]),this._v(", which can search\nAUR for packages that match a given pattern.")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ aursearch aurutils\naur/aurutils 1.5.3-5 "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("55"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    helper tools "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the arch user repository\naur/aurutils-git 1.5.3.r234.g15ef2ab-1 "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("5"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    helper tools "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the arch user repository\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("And "),e("code",[this._v("aursync")]),this._v(" which will download and build packages and ensure packages in the\nrepo are up to date.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("For "),e("code",[this._v("aursync")]),this._v(" to work, we need to add a repo to "),e("code",[this._v("/etc/pacman.conf")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-ini extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ini"}},[a("code",[a("span",{attrs:{class:"token selector"}},[t._v("[mdaffin]")]),t._v("\n"),a("span",{attrs:{class:"token constant"}},[t._v("SigLevel")]),t._v(" "),a("span",{attrs:{class:"token attr-value"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" Optional TrustAll")]),t._v("\n"),a("span",{attrs:{class:"token constant"}},[t._v("Server")]),t._v(" "),a("span",{attrs:{class:"token attr-value"}},[a("span",{attrs:{class:"token punctuation"}},[t._v("=")]),t._v(" https://s3.eu-west-2.amazonaws.com/mdaffin-arch/repo/x86_64/")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[this._v("$ "),e("span",{attrs:{class:"token function"}},[this._v("mkdir")]),this._v(" -p local-repo\n$ repo-add local-repo/mdaffin.db.tar.xz\n$ aursync --repo mdaffin --root local-repo aurutils\n")])])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("p",[t._v("Replace "),a("code",[t._v("mdaffin")]),t._v(" with the name of your repo, this must match the section in\n"),a("code",[t._v("/etc/pacman.conf")]),t._v(". Since we have a remote repo we need to tell "),a("code",[t._v("aursync")]),t._v(" were\nto place the files using "),a("code",[t._v("--root <dir>")]),t._v(" pointing it to a local package cache\n(exact location does not matter).")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[this._v("$ "),e("span",{attrs:{class:"token function"}},[this._v("ls")]),this._v(" local-repo\naurutils-1.5.3-5-any.pkg.tar.xz  mdaffin.db  mdaffin.files\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("To check for and update all the packages in the repo simply add "),e("code",[this._v("-u")]),this._v(" to the\n"),e("code",[this._v("aursync")]),this._v(" command.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[this._v("$ aursync --repo mdaffin --root local-repo -u\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"uploading-to-the-s3-bucket"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#uploading-to-the-s3-bucket","aria-hidden":"true"}},[this._v("#")]),this._v(" Uploading to the S3 Bucket")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("p",[t._v("Now that we have the packages locally we need to upload them to the bucket.\nThis is where "),a("code",[t._v("s3cmd")]),t._v(" comes in, we can tell it to take all the files in our\nlocal cache and upload them to a given directory in the bucket. There are a\ncouple ways to do this, first is the "),a("code",[t._v("put")]),t._v(" or "),a("code",[t._v("cp")]),t._v(" methods which will copy up\nany files we give them, much like the local "),a("code",[t._v("cp")]),t._v(" command. But as our local\ncache grows we will just waste bandwidth and operations uploading the same\nunchanged files over and over again. This is where the "),a("code",[t._v("sync")]),t._v(" command comes in,\nmuch like "),a("code",[t._v("rsync")]),t._v(" it checks the remote to see if the file already exists and if\nit is different from the local copy. Only if it is missing or differs will it\nupload the new files.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("There is one problem, S3 buckets do not support symlinks, which "),e("code",[this._v("repo-add")]),this._v("\ncreates for us. We need to tell it to explicitly copy the files the symlinks\npoint to with the "),e("code",[this._v("--follow-symlinks")]),this._v(" flag. And lastly, we need to set the\npublic permissions on any file we upload with the "),e("code",[this._v("--acl-public")]),this._v(" flag.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[this._v("$ s3cmd "),e("span",{attrs:{class:"token function"}},[this._v("sync")]),this._v(" --follow-symlinks --acl-public local-repo/ s3://mdaffin-arch/repo/x86_64/\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("The packages should now be visible on the Amazon Web Console (or via "),e("code",[this._v("s3cmd ls s3://...")]),this._v(") and installable via "),e("code",[this._v("pacman")]),this._v(".")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ "),a("span",{attrs:{class:"token function"}},[t._v("sudo")]),t._v(" pacsync mdaffin\n$ pacman -Ss aurutils\nmdaffin/aurutils 1.5.3-5 "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("installed"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    helper tools "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the arch user repository\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("And that's it, you have created a repo inside an Amazon S3 bucket. You can add\nmore packages to this repo using the "),e("code",[this._v("aursync")]),this._v(" command above.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"fetching-remote-changes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#fetching-remote-changes","aria-hidden":"true"}},[this._v("#")]),this._v(" Fetching Remote Changes")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("If you want to manage this from multiple computers then you need a way to sync\nup the repos on each system. This can easily be done by reversing the sync\ncommand. For this, we do not need the "),e("code",[this._v("--follow-symlinks")]),this._v(" flag as there are no\nsymlinks in the bucket nor the "),e("code",[this._v("--acl-public")]),this._v(" flag as it does not make sense\nfor a local file. But the "),e("code",[this._v("--delete-removed")]),this._v(" is useful for clearing up files\nthat have been deleted from the remote bucket to stop them from being restored\nwhen you next push changes.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[this._v("$ s3cmd "),e("span",{attrs:{class:"token function"}},[this._v("sync")]),this._v(" --delete-removed s3://mdaffin-arch/repo/x86_64/ local-repo/ \n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("But this will download all files from the remote which can grow quite large\nover time. We really only want to add or remove a few packages at a time and it\nis far more efficient to only download the repo (if it has changed), make any\nchanges to it then upload any required files followed by the changed database.\nWith this, we can also only download a single copy of the database, rather than\nboth copies and manually create the symlinks. Note that we do not need the\n"),e("code",[this._v("--delete-removed")]),this._v(" flag as the database files should always exist both locally\nand remotely.")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ s3cmd "),a("span",{attrs:{class:"token function"}},[t._v("sync")]),t._v(" s3://mdaffin-arch/repo/x86_64/mdaffin."),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("db,files"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(".tar.xz local-repo/\n$ "),a("span",{attrs:{class:"token function"}},[t._v("ln")]),t._v(" -sf local-repo/mdaffin.db.tar.xz local-repo/mdaffin.db\n$ "),a("span",{attrs:{class:"token function"}},[t._v("ln")]),t._v(" -sf local-repo/mdaffin.files.tar.xz local-repo/mdaffin.files\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"removing-a-package"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#removing-a-package","aria-hidden":"true"}},[this._v("#")]),this._v(" Removing a package")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("If you are keeping a full copy of the remote repo locally you can simply\nremove the package and push the changes with the "),e("code",[this._v("--delete-removed")]),this._v(" flag.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[this._v("$ repo-remove local-repo/mdaffin.db.tar.xz aurutils\n$ "),e("span",{attrs:{class:"token function"}},[this._v("rm")]),this._v(" local-repo/aurutils-*.pkg.tar.xz\n$ s3cmd "),e("span",{attrs:{class:"token function"}},[this._v("sync")]),this._v(" --delete-removed --follow-symlinks --acl-public local-repo/ s3://mdaffin-arch/repo/x86_64/\n")])])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[t._v("$ repo-remove local-repo/mdaffin.db.tar.xz aurutils\n$ s3cmd "),a("span",{attrs:{class:"token function"}},[t._v("sync")]),t._v(" --follow-symlinks --acl-public local-repo/mdaffin."),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("db,files"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(",.tar.xz"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" s3://mdaffin-arch/repo/x86_64/\n$ s3cmd "),a("span",{attrs:{class:"token function"}},[t._v("rm")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"s3://mdaffin-arch/repo/x86_64/aurutils-*.pkg.tar.xz"')]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"wrapper-scripts"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#wrapper-scripts","aria-hidden":"true"}},[this._v("#")]),this._v(" Wrapper Scripts")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("p",[t._v("We can automate most of this with a simple wrapper script around "),a("code",[t._v("aursync")]),t._v(".\nSimply save this script somewhere, replace the "),a("code",[t._v("REMOTE_PATH")]),t._v(" and\n"),a("code",[t._v("REPO_NAME")]),t._v(" variables with your own and call it like you would "),a("code",[t._v("aursync")]),t._v(":\n"),a("code",[t._v("./aursync_wrapper PACKAGE")]),t._v(" or "),a("code",[t._v("./aursync_wrapper -u")]),t._v(".")])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{attrs:{class:"token shebang important"}},[t._v("#!/bin/bash")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("# Wraps aursync command to mount an amazon s3 bucket which contains a repository")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("set")]),t._v(" -uo pipefail\n"),a("span",{attrs:{class:"token function"}},[t._v("trap")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'s="),a("span",{attrs:{class:"token variable"}},[t._v("$?")]),t._v('; echo "'),a("span",{attrs:{class:"token variable"}},[t._v("$0")]),t._v(': Error on line "'),a("span",{attrs:{class:"token variable"}},[t._v("$LINENO")]),t._v('": '),a("span",{attrs:{class:"token variable"}},[t._v("$BASH_COMMAND")]),t._v('"; exit '),a("span",{attrs:{class:"token variable"}},[t._v("$s")]),t._v("'")]),t._v(" ERR\n\nREMOTE_PATH"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("s3://mdaffin-arch/repo/x86_64\nLOCAL_PATH"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token variable"}},[t._v("$HOME")]),t._v("/.local/share/arch-repo\nREPO_NAME"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("mdaffin\n\n"),a("span",{attrs:{class:"token function"}},[t._v("mkdir")]),t._v(" -p "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v('"')]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("## Sync remote DB to local ##")]),t._v("\ns3cmd "),a("span",{attrs:{class:"token function"}},[t._v("sync")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REMOTE_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('"')]),t._v("."),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("db,files"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(".tar.xz "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v('/"')]),t._v("\n"),a("span",{attrs:{class:"token function"}},[t._v("ln")]),t._v(" -sf "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.db.tar.xz"')]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.db"')]),t._v("\n"),a("span",{attrs:{class:"token function"}},[t._v("ln")]),t._v(" -sf "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.files.tar.xz"')]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.files"')]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("## Clean up older packages that may or may not have been deleted from the")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("## remote so that we do not reupload them")]),t._v("\n"),a("span",{attrs:{class:"token function"}},[t._v("rm")]),t._v(" -f "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v('/"')]),t._v("*.pkg.tar.xz\n\naursync --repo "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('"')]),t._v(" --root "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v('"')]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$@")]),t._v('"')]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("## Sync local DB to remote ##")]),t._v("\ns3cmd "),a("span",{attrs:{class:"token function"}},[t._v("sync")]),t._v(" --follow-symlinks --acl-public \\\n    "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v('/"')]),t._v("*.pkg.tar.xz \\\n    "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('"')]),t._v("."),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("db,files"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(",.tar.xz"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" \\\n    "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REMOTE_PATH")]),t._v('/"')]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("And to remove a package use the follow script and pass it the package you want\nto remove: "),e("code",[this._v("./del-from-repo aurutils")])])},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{attrs:{class:"token shebang important"}},[t._v("#!/bin/bash")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("# Wraps aursync command to mount an amazon s3 bucket which contains a repository")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("set")]),t._v(" -uo pipefail\n"),a("span",{attrs:{class:"token function"}},[t._v("trap")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'s="),a("span",{attrs:{class:"token variable"}},[t._v("$?")]),t._v('; echo "'),a("span",{attrs:{class:"token variable"}},[t._v("$0")]),t._v(': Error on line "'),a("span",{attrs:{class:"token variable"}},[t._v("$LINENO")]),t._v('": '),a("span",{attrs:{class:"token variable"}},[t._v("$BASH_COMMAND")]),t._v('"; exit '),a("span",{attrs:{class:"token variable"}},[t._v("$s")]),t._v("'")]),t._v(" ERR\n\npackage"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("$"),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("1:?"),a("span",{attrs:{class:"token string"}},[t._v('"Missing package"')]),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nREMOTE_PATH"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("s3://mdaffin-arch/repo/x86_64\nLOCAL_PATH"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token variable"}},[t._v("$HOME")]),t._v("/.local/share/arch-repo\nREPO_NAME"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("mdaffin\n\n"),a("span",{attrs:{class:"token function"}},[t._v("mkdir")]),t._v(" -p "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v('"')]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("## Sync remote DB to local ##")]),t._v("\ns3cmd "),a("span",{attrs:{class:"token function"}},[t._v("sync")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REMOTE_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('"')]),t._v("."),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("db,files"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(".tar.xz "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v('/"')]),t._v("\n"),a("span",{attrs:{class:"token function"}},[t._v("ln")]),t._v(" -sf "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.db.tar.xz"')]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.db"')]),t._v("\n"),a("span",{attrs:{class:"token function"}},[t._v("ln")]),t._v(" -sf "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.files.tar.xz"')]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.files"')]),t._v("\n\nrepo-remove "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('.db.tar.xz"')]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$@")]),t._v('"')]),t._v("\ns3cmd "),a("span",{attrs:{class:"token function"}},[t._v("sync")]),t._v(" --follow-symlinks --acl-public "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$LOCAL_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$REPO_NAME")]),t._v('"')]),t._v("."),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("db,files"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(",.tar.xz"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REMOTE_PATH")]),t._v('/"')]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" package "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$@")]),t._v('"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    s3cmd "),a("span",{attrs:{class:"token function"}},[t._v("rm")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"'),a("span",{attrs:{class:"token variable"}},[t._v("$REMOTE_PATH")]),t._v("/"),a("span",{attrs:{class:"token variable"}},[t._v("$package")]),t._v('-*.pkg.tar.xz"')]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("done")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"amazon-aws-s3-alternatives"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#amazon-aws-s3-alternatives","aria-hidden":"true"}},[this._v("#")]),this._v(" Amazon AWS S3 Alternatives")])}],n=a(0),r=Object(n.a)({},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("div",{staticClass:"content"},[t._m(0),t._v(" "),t._m(1),t._v(" "),a("p",[t._v("In this three-part series, I will show you one way to simplify and manage\nmultiple Arch Linux systems using a custom repo, a set of meta-packages and a\nscripted installer. Each part is standalone and can be used by its self, but\nthey are designed to build upon and complement each other each focusing on a\ndifferent part of the problem.")]),t._v(" "),a("ul",[t._m(2),t._v(" "),a("li",[a("strong",[t._v("Part 2:")]),t._v(" "),a("router-link",{attrs:{to:"/linux/archlinux-meta-packages/"}},[t._v("Managing Arch Linux with Meta Packages")])],1),t._v(" "),a("li",[a("strong",[t._v("Part 3:")]),t._v(" "),a("router-link",{attrs:{to:"/linux/archlinux-installer/"}},[t._v("Creating a Custom Arch Linux Installer")])],1)]),t._v(" "),a("p",[t._v("When you use Arch Linux for any length of time you start collecting sets of\n"),a("a",{attrs:{href:"https://aur.archlinux.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("AUR"),a("OutboundLink")],1),t._v(" packages that you frequently use. Now, Arch Linux has loads of "),a("a",{attrs:{href:"https://wiki.archlinux.org/index.php/AUR_helpers",target:"_blank",rel:"noopener noreferrer"}},[t._v("AUR\nhelpers"),a("OutboundLink")],1),t._v(" that make managing AUR packages painless, but when you start using\narch on multiple systems it becomes annoying and time consuming to rebuild AUR\npackages on each system. In this post, I will show you how to use an Amazon S3\nbucket to create a cheap, low maintenance Arch Linux repository. As well as\nmaking use of the "),a("code",[t._v("aurutils")]),t._v(" package to make building and upgrading AUR packages\na painless exercise.")]),t._v(" "),t._m(3),t._v(" "),t._m(4),t._v(" "),t._m(5),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/AladW/aurutils",target:"_blank",rel:"noopener noreferrer"}},[t._v("aurutils"),a("OutboundLink")],1),t._v(": a set of utilities that make it easy to manage/update a repo with\nAUR packages.")]),t._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/s3tools/s3cmd",target:"_blank",rel:"noopener noreferrer"}},[t._v("s3cmd"),a("OutboundLink")],1),t._v(": a tool to upload and download files from an AWS S3 bucket.")]),t._v(" "),a("li",[t._v("base-devel: needed to build aurutils and other packages.")])]),t._v(" "),a("p",[t._v("To install all of these run the following.")]),t._v(" "),t._m(6),t._m(7),t._v(" "),t._m(8),t._m(9),t._v(" "),t._m(10),t._m(11),t._v(" "),a("p",[t._v("Sign in to "),a("a",{attrs:{href:"https://s3.console.aws.amazon.com/s3/home?region=us-east-1",target:"_blank",rel:"noopener noreferrer"}},[t._v("Amazon's console"),a("OutboundLink")],1),t._v(" and head to the "),a("a",{attrs:{href:"https://s3.console.aws.amazon.com/s3/home?region=us-east-1",target:"_blank",rel:"noopener noreferrer"}},[t._v("Amazon S3"),a("OutboundLink")],1),t._v(" interface.\nYou will be required to enter your credit card details in order to create the\nbucket, this should be free for the first year if you stay under 5GB of storage\nand "),a("a",{attrs:{href:"https://aws.amazon.com/s3/pricing/",target:"_blank",rel:"noopener noreferrer"}},[t._v("fairly cheap"),a("OutboundLink")],1),t._v(" after that.")]),t._v(" "),a("p",[t._v("Click on the create bucket button.")]),t._v(" "),t._m(12),t._v(" "),a("p",[t._v("Name your bucket and select the region you want to host it in.")]),t._v(" "),t._m(13),t._v(" "),t._m(14),t._v(" "),t._m(15),t._v(" "),a("p",[t._v("After you should have one public bucket listed like so.")]),t._v(" "),t._m(16),t._v(" "),t._m(17),t._v(" "),a("p",[t._v("We now need to create an access key that has permissions to edit this bucket.\nWe can do this by creating a new restricted user that only have access to the\nAmazon S3 buckets.")]),t._v(" "),a("p",[t._v("Head over to the "),a("a",{attrs:{href:"https://console.aws.amazon.com/iam/home#/users",target:"_blank",rel:"noopener noreferrer"}},[t._v("AWS IAM management console"),a("OutboundLink")],1),t._v(" and add a new user. Then enter\nthe username and ensure "),a("em",[t._v("Programmatic access")]),t._v(" check box is selected.")]),t._v(" "),t._m(18),t._v(" "),t._m(19),t._v(" "),t._m(20),t._v(" "),t._m(21),t._v(" "),t._m(22),t._v(" "),t._m(23),t._v(" "),t._m(24),t._v(" "),a("p",[t._v("Keep this key secret as it will give anyone with it the ability to\ncreate/modify your buckets. If you lose the key or no longer require it then\nhead to the user page and remove it from the user.")]),t._v(" "),t._m(25),t._v(" "),t._m(26),a("p",[t._v("And ensure it is only readable by your user")]),t._v(" "),t._m(27),t._m(28),t._v(" "),t._m(29),t._v(" "),t._m(30),t._m(31),t._v(" "),t._m(32),t._v(" "),t._m(33),a("p",[t._v("Give your repo a unique name by replacing "),a("code",[t._v("[mdaffin]")]),t._v(" with something else.\nChange the URL to that of your bucket/repo path. You can get the exact URL by\ncreating a file inside the directory and getting a link to that file from the\n"),a("a",{attrs:{href:"https://s3.console.aws.amazon.com/s3/home",target:"_blank",rel:"noopener noreferrer"}},[t._v("Amazon Web Console"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("p",[t._v("Now we can create the repo and upload our first package to it. For this, we are\ngoing to rebuild the aurutils package as it will be handy to have that stored\nin our repo. But first, we need to create a directory to store the repo as well\nas initialise the database files.")]),t._v(" "),t._m(34),t._m(35),t._v(" "),a("p",[t._v("If all goes well you should end up with the package and repo database inside\nthe cache directory.")]),t._v(" "),t._m(36),t._m(37),t._v(" "),t._m(38),t._m(39),t._v(" "),t._m(40),t._v(" "),t._m(41),t._v(" "),t._m(42),t._m(43),t._v(" "),t._m(44),t._m(45),t._v(" "),t._m(46),t._v(" "),t._m(47),t._v(" "),t._m(48),t._m(49),t._v(" "),t._m(50),t._m(51),t._v(" "),t._m(52),t._v(" "),t._m(53),a("p",[t._v("However, this cannot be done if we are only downloading the database as we will\nbe missing more of the packages and thus end up deleting most of our remote\nrepo. Instead, we should update the local cache to remove the package, push only\nthe repository files then tell the remote to delete the package.")]),t._v(" "),t._m(54),t._m(55),t._v(" "),t._m(56),t._v(" "),t._m(57),t._m(58),t._v(" "),t._m(59),t._m(60),t._v(" "),a("p",[t._v("If you don't wish to use Amazon buckets there are some alternatives such as\n"),a("a",{attrs:{href:"https://m.do.co/c/8fba3fc95fef",target:"_blank",rel:"noopener noreferrer"}},[t._v("Digital Ocean Spaces"),a("OutboundLink")],1),t._v(" or "),a("a",{attrs:{href:"https://cloud.google.com/storage/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Google Cloud Buckets"),a("OutboundLink")],1),t._v(" that can be used in place. Some\nare compatible with the S3 API and thus can be used with the instructions above\nwhile others require a different way to sync the changes. For example, if you\nhave a static file server somewhere you can use "),a("code",[t._v("rsync")]),t._v(" in place of most\n"),a("code",[t._v("s3cmd")]),t._v(" with the relevant flags set.")]),t._v(" "),a("p",[a("em",[a("a",{attrs:{href:"https://www.reddit.com/r/archlinux/comments/7v7g4w/managing_multiple_arch_linux_systems_with/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Discuss on Reddit"),a("OutboundLink")],1)])])])},s,!1,null,null,null);r.options.__file="index.md";e.default=r.exports}}]);